{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e062b7c1",
   "metadata": {},
   "source": [
    "# Results analysis\n",
    "This notebook was used to analyse the results and produce graphics included in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ddc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159deb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tensorboard_scalars(logdir, tag_name):\n",
    "    \"\"\"Read a scalar from a single TensorBoard log directory.\"\"\"\n",
    "    event_acc = EventAccumulator(logdir)\n",
    "    event_acc.Reload()\n",
    "\n",
    "    #print(event_acc.Tags()['scalars'])  # Look for the exact tag name here\n",
    "\n",
    "    if tag_name not in event_acc.Tags()['scalars']:\n",
    "        raise ValueError(f\"Tag '{tag_name}' not found in TensorBoard logs at {logdir}.\")\n",
    "\n",
    "    events = event_acc.Scalars(tag_name)\n",
    "    steps = [e.step for e in events]\n",
    "    values = [e.value for e in events]\n",
    "\n",
    "    return pd.DataFrame({'step': steps, 'value': values, 'run': logdir})\n",
    "\n",
    "def aggregate_experiments(experiments, tag_name):\n",
    "    \"\"\"Combine scalar data from multiple TensorBoard runs into a single DataFrame.\"\"\"\n",
    "    df_list = []\n",
    "\n",
    "    for logdir in experiments:\n",
    "        try:\n",
    "            df = read_tensorboard_scalars(logdir, tag_name)\n",
    "            df_list.append(df)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "tag_name = \"combined Reward-mean\"\n",
    "results_path = \"/home/dave/dev/Reasoning/runs/stimulus-response/2026/02/\"\n",
    "experiments_1 = [\n",
    "    results_path + \"20/11:00:51\", \n",
    "    results_path + \"20/11:19:29\", \n",
    "    results_path + \"20/12:01:30\", \n",
    "    results_path + \"20/12:42:20\", \n",
    "    results_path + \"20/13:21:58\", \n",
    "\n",
    "    results_path + \"21/19:36:15\", \n",
    "    results_path + \"21/20:05:21\", \n",
    "    results_path + \"21/20:26:36\", \n",
    "]\n",
    "experiments_2 = [\n",
    "    results_path + \"20/14:10:28\", \n",
    "    results_path + \"20/14:35:00\", \n",
    "    results_path + \"20/14:58:15\", \n",
    "    results_path + \"20/15:21:28\", \n",
    "    results_path + \"20/15:44:49\", \n",
    "\n",
    "    results_path + \"21/17:47:18\", \n",
    "    results_path + \"21/18:14:43\", \n",
    "    results_path + \"21/18:44:37\", \n",
    "]\n",
    "experiments_3 = [\n",
    "    results_path + \"20/16:06:03\", \n",
    "    results_path + \"20/16:52:52\", \n",
    "    results_path + \"20/17:42:44\", \n",
    "    results_path + \"20/19:00:14\",  # used for individual plot (1x)\n",
    "    results_path + \"20/20:37:40\",\n",
    "    \n",
    "    results_path + \"21/07:02:00\",\n",
    "    results_path + \"21/14:17:19\",\n",
    "    results_path + \"21/15:07:21\",\n",
    "]\n",
    "\n",
    "combined_df_1 = aggregate_experiments(experiments_1, tag_name)\n",
    "combined_df_2 = aggregate_experiments(experiments_2, tag_name)\n",
    "combined_df_3 = aggregate_experiments(experiments_3, tag_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164bc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df_1.columns)\n",
    "#for i in range(len(combined_df_1)):\n",
    "#    print(combined_df_1.iloc[i][\"step\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd70342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define periods\n",
    "# training_steps = 12000\n",
    "# evaluate_steps = 1000\n",
    "# few_shot_training_steps = [10, 10, 20, 40, 80, 160, 320, 640, 1280]    \n",
    "\n",
    "periods = [\n",
    "    # Pretraining phase (inclusive)\n",
    "    [\"Training (old)\",   100, 12000, 0],\n",
    "    [\"Original data\", 12100, 13000, 0],\n",
    "    [\"Few-shot data\", 13100, 14000, 0],\n",
    "\n",
    "    # Few-shot phase (inclusive)\n",
    "    [\"Training (new)\", 14011, 14011, 10],  # +10\n",
    "    [\"Original data\", 14100, 15011, 10],\n",
    "    [\"Few-shot data\", 15100, 16011, 10],\n",
    "\n",
    "    [\"Training (new)\", 16021, 16021, 20],  # +10\n",
    "    [\"Original data\", 16100, 17021, 20],\n",
    "    [\"Few-shot data\", 17100, 18021, 20],\n",
    "\n",
    "    [\"Training (new)\", 18041, 18041, 40],  # +20\n",
    "    [\"Original data\", 18100, 19041, 40],\n",
    "    [\"Few-shot data\", 19100, 20041, 40],\n",
    "\n",
    "    [\"Training (new)\", 20081, 20081, 80],  # +40\n",
    "    [\"Original data\", 20100, 21081, 80],\n",
    "    [\"Few-shot data\", 21100, 22081, 80],\n",
    "\n",
    "    [\"Training (new)\", 22100, 22161, 160],  # +80\n",
    "    [\"Original data\", 22200, 23161, 160],\n",
    "    [\"Few-shot data\", 23200, 24161, 160],\n",
    "\n",
    "    [\"Training (new)\", 24200, 24321, 320],  # +160\n",
    "    [\"Original data\", 24400, 25321, 320],\n",
    "    [\"Few-shot data\", 25400, 26321, 320],\n",
    "\n",
    "    [\"Training (new)\", 26400, 26641, 640],  # +320\n",
    "    [\"Original data\", 26700, 27641, 640],\n",
    "    [\"Few-shot data\", 27700, 28641, 640],\n",
    "\n",
    "    [\"Training (new)\", 28700, 29281, 1280],  # +640\n",
    "    [\"Original data\", 29300, 30281, 1280],\n",
    "    [\"Few-shot data\", 30300, 31281, 1280],\n",
    "\n",
    "    [\"Training (new)\", 31300, 32561, 2560],  # +1280\n",
    "    [\"Original data\", 32600, 33561, 2560],\n",
    "    [\"Few-shot data\", 33600, 34561, 2560],\n",
    "]\n",
    "\n",
    "# Split into periods\n",
    "def split_few_shot_periods(df, offset:int) : #, label:str):\n",
    "    rows = []\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for period in periods:\n",
    "        period_name = period[0] \n",
    "        if period_name.startswith(\"Training\"):\n",
    "            continue\n",
    "\n",
    "        t1 = period[1] + offset\n",
    "        t2 = period[2] + offset\n",
    "        cumulative_steps = period[3]\n",
    "        # between() has inclusive bounds        \n",
    "        df_period = df[df['step'].between(t1, t2)].copy()\n",
    "        combined_name = f\"{period_name}[{cumulative_steps}\"\n",
    "        print(f\"{combined_name}: {t1} --> {t2} has {len(df_period)} samples.\")\n",
    "\n",
    "        mean = df_period[\"value\"].mean()\n",
    "        std = df_period[\"value\"].std()\n",
    "        min = df_period[\"value\"].min()\n",
    "        max = df_period[\"value\"].max()\n",
    "        cols = {\n",
    "            \"label\": period_name,\n",
    "            \"t\": cumulative_steps,\n",
    "            \"mean\": mean,\n",
    "            \"std\": std,\n",
    "            \"min\": min,\n",
    "            \"max\": max,\n",
    "        }\n",
    "        rows.append(cols)\n",
    "    df = pd.DataFrame(rows)\n",
    "    #df[\"label\"] = label\n",
    "    return df\n",
    "\n",
    "df_1 = split_few_shot_periods(combined_df_1, offset=0)\n",
    "df_2 = split_few_shot_periods(combined_df_2, offset=0)\n",
    "df_3 = split_few_shot_periods(combined_df_3, offset=-6000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadc00ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_period(df, offset:int) : #, label:str):\n",
    "    t1 = 0\n",
    "    t2 = 0\n",
    "    for period in periods:\n",
    "        period_name = period[0] \n",
    "        if not period_name.startswith(\"Training (old)\"):\n",
    "            continue\n",
    "\n",
    "        t1 = max(100, period[1] + offset)\n",
    "        t2 = period[2] + offset\n",
    "\n",
    "        # between() has inclusive bounds        \n",
    "        df_period = df[df['step'].between(t1, t2)].copy()\n",
    "        print(f\"{period_name}: {t1} --> {t2} has {len(df_period)} samples.\")\n",
    "        return df_period\n",
    "    return None\n",
    "\n",
    "df_training_1 = split_training_period(combined_df_1, offset=0)\n",
    "df_training_2 = split_training_period(combined_df_2, offset=0)\n",
    "df_training_3 = split_training_period(combined_df_3, offset=-6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f920839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(df, window_size=8):\n",
    "    # Sort the DataFrame to ensure time series order\n",
    "    df = df.sort_values(by=['step'])\n",
    "    \n",
    "    # Apply the rolling mean grouped by 'label'\n",
    "    df['value-smoothed'] = df.groupby('run')['value'].transform(lambda s: s.rolling(window=window_size, min_periods=1).mean())\n",
    "    \n",
    "    return df.copy()\n",
    "\n",
    "df_training_1_sm = moving_average(df_training_1)\n",
    "df_training_1_sm[\"label\"] = \"Entangled (dense ANN); LR: 0.0001\"\n",
    "\n",
    "df_training_2_sm = moving_average(df_training_2)\n",
    "df_training_2_sm[\"label\"] = \"Entangled (dense ANN); LR: 0.001\"\n",
    "\n",
    "df_training_3_sm = moving_average(df_training_3)\n",
    "df_training_3_sm[\"label\"] = \"Disentangled memory; LR: 0.1\"\n",
    "\n",
    "df_training = pd.concat([df_training_1_sm, df_training_2_sm, df_training_3_sm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0322f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot(\n",
    "    plot_data,\n",
    "    title, \n",
    "    x_label,\n",
    "    y_label, \n",
    "    file_name,\n",
    "):\n",
    "    #plt.figure(figsize=(10, 8))\n",
    "    for label in plot_data['label'].unique():\n",
    "        subset = plot_data[plot_data['label'] == label]\n",
    "        sns.lineplot(data=subset, x='step', y='value-smoothed', label=label)\n",
    "    \n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.legend(title=\"Condition\")\n",
    "    plt.savefig(file_name)\n",
    "    plt.show()\n",
    "\n",
    "plot(\n",
    "    plot_data = df_training, \n",
    "    title = \"Reward during training (Epsilon=0.1)\",\n",
    "    x_label = \"Minibatch (batch size: 16)\",\n",
    "    y_label = \"Mean reward (per step)\",\n",
    "    file_name = \"training.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_subplots(\n",
    "    plot_data:list[pd.DataFrame],\n",
    "    subtitles:list[str],\n",
    "    title, \n",
    "    x_label,\n",
    "    y_label, \n",
    "    file_name,\n",
    "):\n",
    "    \"\"\"\n",
    "    This plot is for the few-shot results.\n",
    "    \"\"\"\n",
    "    num_subplots = len(plot_data)\n",
    "    fig, axes = plt.subplots(1, num_subplots, figsize=(15, 5), sharey=True)\n",
    "\n",
    "    for i in range(num_subplots):\n",
    "        axes[i].set_title(subtitles[i])\n",
    "        axes[i].set_xscale('log')  # Set the x-axis to log scale\n",
    "        axes[i].set_xlabel(x_label)\n",
    "        #axes[i].tick_params(labelleft=True)\n",
    "        if i == 0:\n",
    "           axes[i].set_ylabel(y_label)\n",
    "\n",
    "        sub_plot_data = plot_data[i]\n",
    "        for label in sub_plot_data['label'].unique():\n",
    "            #print(f\"Label={label}\")\n",
    "            subset = sub_plot_data[sub_plot_data['label'] == label]\n",
    "            \n",
    "            sns.lineplot(ax=axes[i], data=subset, x='t', y='mean', marker=\"o\", label=label)\n",
    "            \n",
    "            # Add the shaded standard deviation\n",
    "            axes[i].fill_between(\n",
    "                subset['t'],\n",
    "                subset['mean'] - subset['std'],\n",
    "                subset['mean'] + subset['std'],\n",
    "                #subset['min'],\n",
    "                #subset['max'],\n",
    "                alpha=0.2,\n",
    "            )\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.legend(title=\"Condition\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec088624",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subplots(\n",
    "    plot_data = [df_2, df_1, df_3], \n",
    "    subtitles = [\n",
    "        \"Entangled (dense ANN); LR: 0.001\",\n",
    "        \"Entangled (dense ANN); LR: 0.0001\",\n",
    "        \"Disentangled memory; LR: 0.1\",\n",
    "    ],\n",
    "    title = \"Performance on original and new data during few-shot learning.\", \n",
    "    x_label = \"Few-shot batches (size:16); max. Eps. len.:10\",\n",
    "    y_label = \"Mean reward (per step)\", \n",
    "    file_name = 'few_shot_evaluation.png',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3c5b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_3.columns)\n",
    "df_3['step'] = df_3['t']\n",
    "df_3['value-smoothed'] = df_3['mean']\n",
    "\n",
    "def plot_1x(\n",
    "    plot_data,\n",
    "    title, \n",
    "    x_label,\n",
    "    y_label, \n",
    "    file_name,\n",
    "):\n",
    "    #plt.figure(figsize=(10, 8))\n",
    "    for label in plot_data['label'].unique():\n",
    "        subset = plot_data[plot_data['label'] == label]\n",
    "        sns.lineplot(data=subset, x='step', y='value-smoothed', marker=\"o\", label=label)\n",
    "    \n",
    "    plt.xscale('log')  # Set the x-axis to log scale\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.legend(title=\"Condition\", loc='lower right')\n",
    "    plt.savefig(file_name)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_1x(\n",
    "    plot_data = df_3, \n",
    "    title = \"Performance on original and new data during few-shot learning (1x).\", \n",
    "    x_label = \"Few-shot batches (size:16); max. Eps. len.:10\",\n",
    "    y_label = \"Mean reward (per step)\",\n",
    "    file_name = \"few_shot_evaluation_separate.png\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
