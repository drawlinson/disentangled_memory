{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b723ae8",
   "metadata": {},
   "source": [
    "# Dataset generator\n",
    "This notebook allows you to generate a dataset similar to the one used in the paper.\n",
    "\n",
    "It assumes that Ollama and the desired LLM are installed on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa7cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f035e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "OLLAMA_HOST = \"http://127.0.0.1:11434\"  # default Ollama API endpoint\n",
    "MODEL_NAME = \"mistral\"                  # must match the local Ollama model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c586fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_generate(prompt: str, max_tokens:int=5, temperature:float=0.2):\n",
    "    \"\"\"\n",
    "    Sends prompt to Ollama local API and returns text tokens.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    r = requests.post(f\"{OLLAMA_HOST}/v1/completions\", json=payload)\n",
    "    r.raise_for_status()\n",
    "    response = r.json()\n",
    "    #print(response)\n",
    "\n",
    "    # Ollama returns a list of completions (usually just one)\n",
    "    text = response['choices'][0]['text']\n",
    "    return text\n",
    "\n",
    "def clean_first_token(text:str) -> str:\n",
    "    tokens = text.split()\n",
    "    return tokens[0].lower().strip().replace(\",\", \"\").replace(\".\", \"\").replace(\"\\\"\", \"\").replace(\":\", \"\").replace(\"!\", \"\").replace(\"?\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7695cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent never sees true label of object, only perceptions of it as produced by the LLM.\n",
    "# Perceptual questions should be observable phenomena, not facts which require experience to learn.\n",
    "# Perceptual questions cost time; the agent must eat things when hungry.\n",
    "\n",
    "# LLM used as world simulation and as LTM\n",
    "\n",
    "# Create scenarios statistically. \n",
    "# Fill in the perceptions from the LLM\n",
    "# Original list of encounters was generated by LLM but had far too many cats.\n",
    "# Classes (keys) are observable; precise scenarios are not observable but used in world model\n",
    "scenario_classes = {\n",
    "    \"maybe something to eat\": [\n",
    "        # Food\n",
    "        \"cheese\",\n",
    "        \"tomato\",\n",
    "        \"carrot\",\n",
    "        \"cauliflower\",\n",
    "        \"radish\",\n",
    "\n",
    "        # Poisons\n",
    "        \"deadly nightshade\",\n",
    "        \"slug pellets\",\n",
    "        \"fly agaric mushroom\",\n",
    "    ],\n",
    "    \"bird\": [\n",
    "        # Predatory birds\n",
    "        \"eagle\",\n",
    "        \"hawk\",\n",
    "        \"falcon\",\n",
    "\n",
    "        # Harmless birds\n",
    "        \"sparrow\",\n",
    "        \"pigeon\",\n",
    "    ],  # yes birds are animals too\n",
    "    \"land animal\": [\n",
    "        # Dangerous?\n",
    "        \"cat\",\n",
    "        \"dog\",\n",
    "        \"fox\",\n",
    "        \"snake\",\n",
    "        \"farmer\",\n",
    "\n",
    "        # Harmless mammals\n",
    "        \"beetle\",\n",
    "        \"horse\",\n",
    "        \"mouse\",\n",
    "        \"capybara\",\n",
    "    ],\n",
    "    \"plant\": [\n",
    "        # Plants\n",
    "        \"tree\",\n",
    "        \"grass\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "actions = [\n",
    "    \"Go to it\",\n",
    "    \"Eat it\",\n",
    "    \"Hide\",\n",
    "    \"Run away\",\n",
    "]\n",
    "scenario_prompt = \"You are a mouse in a garden and you see a\"\n",
    "\n",
    "# Attributes which can be perceived\n",
    "perceptions = [\n",
    "    \"Does it look like a mouse?\",\n",
    "    \"Is it bigger than a mouse?\",\n",
    "    \"Does it smell tasty?\",\n",
    "    \"Does it have a long tail?\",\n",
    "    \"Does it have four legs?\",\n",
    "    \"Is it red?\",\n",
    "    \"Is it green?\",\n",
    "    \"Is it noisy?\",\n",
    "    \"Is it watching you?\",\n",
    "    \"Is it coming towards you?\",\n",
    "    \n",
    "]\n",
    "# Used in environment update to determine reward from actions\n",
    "attributes = [\n",
    "    \"Is it edible?\",  # +ve reward if eaten\n",
    "    \"Is it poisonous?\",  # -ve reward if eaten\n",
    "    \"Does it eat mice?\",  # -ve reward on go-to or eat-it +ve if hide / run-away\n",
    "    \"Is it friendly?\",  # +ve reward if approached; -ve if hide\n",
    "    \"Does it chase mice?\", # -ve reward if run away\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c6d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset options\n",
    "temperature = 0.7\n",
    "num_scenarios = 1000\n",
    "scenarios_filename = \"new_scenarios.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd1a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate 1000 scenarios\n",
    "scenarios = []\n",
    "scenario_class_list = list(scenario_classes.keys())\n",
    "num_classes = len(scenario_class_list)\n",
    "\n",
    "for i in range(num_scenarios):\n",
    "\n",
    "    # Pick a random class\n",
    "    n = np.random.randint(0, num_classes)\n",
    "    k = scenario_class_list[n]\n",
    "\n",
    "    # Get specific instances for that class\n",
    "    # Pick a specific encounter\n",
    "    scenario_list = list(scenario_classes[k])\n",
    "    m = np.random.randint(0, len(scenario_list))\n",
    "\n",
    "    # Add to list of scenarios\n",
    "    scenario_class = k\n",
    "    scenario_object = scenario_list[m]\n",
    "    scenario = [scenario_class, scenario_object]\n",
    "    scenarios.append(scenario)\n",
    "    print(f\"{i}/{num_scenarios}: {scenario}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_answers(thing:str, yes_no_question:str):\n",
    "    prompt = f\"Respond with one word, Yes or No. {scenario_prompt} {thing}. {yes_no_question}\"\"\"\n",
    "    print(prompt)\n",
    "    n = 0\n",
    "    max_tries = 10\n",
    "    while(n < max_tries):\n",
    "        n += 1\n",
    "        response = ollama_generate(prompt, temperature=temperature)\n",
    "        word = clean_first_token(response)\n",
    "        if word == \"yes\" or word == \"no\":\n",
    "            return word\n",
    "    return \"?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8234807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_data = {}\n",
    "\n",
    "def append_sample(k, v):\n",
    "    if k not in col_data.keys():\n",
    "        col_data[k] = []\n",
    "    col_data[k].append(v)\n",
    "\n",
    "for i in range(num_scenarios):\n",
    "    print(f\"{i}/{num_scenarios} \")\n",
    "    object_class = scenarios[i][0]\n",
    "    object_name = scenarios[i][1]\n",
    "    append_sample(\"Class\", object_class)\n",
    "    append_sample(\"Object\", object_name)\n",
    "\n",
    "    for q in perceptions:\n",
    "        answer = sample_answers(\n",
    "            thing = object_name, \n",
    "            yes_no_question = q, \n",
    "        )\n",
    "        append_sample(q, answer)\n",
    "        \n",
    "    for q in attributes:\n",
    "        answer = sample_answers(\n",
    "            thing = object_name, \n",
    "            yes_no_question = q, \n",
    "        )\n",
    "        append_sample(q, answer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36642344",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(col_data)\n",
    "print(df.head(10))\n",
    "df.to_csv(scenarios_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
